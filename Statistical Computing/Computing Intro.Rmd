---
title: "Computing Intro"
author: "Jake Spiteri"
date: "09/12/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Section 4 --- Exercises

## Question 1
Computers do not represent most real numbers exactly. Rather, a real number is approximatedby the nearest real number that can be represented exactly (floating point number), given somescheme for representing real numbers as fixed length binary sequences. Often the approximation is not noticeable, but it can make a big difference relative to exact arithmetic (imagine thatyou want to know the difference between 2 distinct real numbers that are approximated by thesamebinary sequence, for example).

One consequence of working infinite precision arithmeticis that for any numberx, there is a small number $\epsilon$ for which $x+\epsilon$is indistinguishable from $x$ (with any number smaller than this having the same property).

### Part (a)
```{r}
eps <- 1
x <- 1
while(x+eps != x) 
  eps <- eps/2
eps/x
```

### Part (b)
```{r}
eps <- 1e-18; x <- 1
while(x == x+eps)
  eps <- eps+1e-18
eps
```

### Part (c)
```{r}
2*eps
.Machine$double.eps
```

### Part (d)
```{r}
eps <- 1; x <- 1/4
while(x+eps != x) 
  eps <- eps/2
eps/x
```

### Part (e)


### Part (f)


## Question 2
### Part (a)
R  is  an  interpreted  language.   Instructions  are  interpreted  ‘on  the  fly’.   This  tends  to  meanthat it is efficient to code in such a way that many calculations are performed per interpretedinstruction. Often this implies that loops should be avoided, otherwise R can spend much moretime interpreting the instructions to carry out a calculation than on performing the calculation itself.

```{r}
# rewrite this
system.time({
X <- matrix(runif(100000),1000,100)
z <- rep(0,1000)
for(i in 1:1000){
  for(j in 1:100) z[i] <- z[i] + X[i,j]
}
})


# using apply
system.time({
z <- apply(X, 1, sum)
})

# using rowSums
system.time({
z <- rowSums(X)
})

# using vectorization
system.time({
ones <- rep(1,100)
z <- X %*% ones
})

```

### Part (b)
```{r}
# rewrite the following
system.time({
n <- 100000
z <- rnorm(n)
zneg <- 0; j <- 1
for(i in 1:n){
  if(z[i]<0){
    zneg[j] <- z[i]
    j <- j + 1
  }
}
})

# using apply
n <- 100000
z <- rnorm(n)
system.time(
zneg <- lapply(z, function(x) x[x<0])
)

system.time(
zneg <- z[z<0]
)
```


## Question 3
```{r}
set.seed(1)
n <- 1000
A <- matrix(runif(n*n),n,n) 
x <- runif(n)

t(x) %*% A %*% x
sum(diag(A))
sum(diag((t(A) %*% diag(x) %*% A)))
```

## Question 4
We will solve the linear system $Ax = x$ for $x$, where $y$ is a known $n$ vector and $A$ is a known $n \times n$ matrix. We will solve this by forming $A^{-1}$, and directly without forming the inverse of $A$.
### Part (a)
We first create an $A, x$, and $y$ satisfying $Ax=y$.
```{r}
set.seed(0)
n <- 1000
A <- matrix(runif(n*n),n,n) 
x.true <- runif(n)
y <- A%*%x.true
```

### Part (b)
We form the inverse of $A$ explicitly and then form $x_1 = A^{-1}y$. Note that inverting the matrix takes a long time.
```{r}
A.inv <- solve(A)
x.1 <- A.inv %*% y
mean(abs(x.1 - x.true))
```

### Part (c)
We now directly solve the lienar system for $x$.
```{r}
x.2 <- solve(A, y)
mean(abs(x.2 - x.true))
```

### Part (d)
In part (b) and (c) we see that solving directly for $x$ is much faster, and results in less numerical error.


## Question 5
Write an R function which takes an un-ordered vector of observations x and returns the values of the empirical c.d.f. for each value, in the order corresponding to the original $x$ vector. (See ?sort.int.)
```{r}
empirical.cdf <- function(x) {
  # sort x and store length
  x.sorted <- sort(x); n <- length(x)
  
  # initialise cdf.hat and calculate
  cdf.hat <- rep(0,n)
  for(i in 1:n) {
    cdf.hat[i] <- sum((x.sorted < x.sorted[i]))/n
  }
  
  # map cdf values to original unsorted x
  cdf.hat <- cdf.hat[order(x)]
  
  # return cdf.hat
  return(cdf.hat)
}

empirical.cdf(runif(100))
```

### Part (b)
Modify your function to take an extra argument plot.cdf, which when TRUE will cause the empirical c.d.f. to be plotted as a step function, over a suitable $x$ range.

```{r}
empirical.cdf <- function(x, plot.cdf=TRUE) {
  # sort x and store length
  x.sorted <- sort(x); n <- length(x)
  
  # initialise cdf.hat and calculate
  cdf.hat <- rep(0,n)
  for(i in 1:n) {
    cdf.hat[i] <- sum((x.sorted < x.sorted[i]))/n
  }
  
  # cases: if plot.cdf is TRUE then plot cdf; else return cdf.hat
  if(plot.cdf) {
    # create stepfun object
    step.fn <- stepfun(x.sorted[-n], cdf.hat)
    plot(step.fn)
  } else {
      # map cdf values to original unsorted x
      cdf.hat <- cdf.hat[order(x)]
      return(cdf.hat)
  }
}

empirical.cdf(runif(10))
```

## Question 6

### Part (a)
Write an R function which takes arguments equal length vectors $x$ and $z$ and returns the vector of values of Robenbrock's functions at each $x[i], z[i]$.
```{r}
rb <- function(x,z) {100*(z-x^2)^2 + (1-x)^2}
rb(seq(-10,10), seq(-10,10))
```

### Part (b)
Produce a contour plot over the rectangle $-1.5 < x < 1.5$, $-0.5 < z < 1.5$.
```{r}
# produce a matrix of evaluations of the rosenbrock function
x.seq <- seq(-1.5, 1.5, length.out=100)
z.seq <- seq(-0.5, 1.5, length.out=100)
cont.mat <- outer(x.seq,
                  z.seq,
                  Vectorize(function(x,z) rb(x,z)))
contour(x=x.seq, y=z.seq, cont.mat)
```

### Part (c)
We form the contour of the `log10` of the function, and adjust the levels argument.
```{r}
cont.mat <- outer(x.seq,
                  z.seq,
                  Vectorize(function(x,z) log10(rb(x,z))))
contour(x.seq, z.seq, cont.mat, levels = seq(-0.5,2.5, 0.5))
```

### Part (d)
Write an R function rb.grad which takes single values for each of x and z as arguments, and returns the gradient vector of Rosenbrock’s function, i.e. a vector of length 2 containing ∂f/∂x and ∂f/∂z evaluated at the supplied x,z values (you need to first differentiate f algebraically to do this).
```{r}
rb.grad <- function(x,z) {
  d <- deriv(expression(100*(z-x^2)^2 + (1-x)^2), namevec=c("x", "z"), func=TRUE)
  attr(d(x,z), "gradient")
}

rb.grad(1,4)
```

### Part (e)
Test the `rb.grad` function above via finite differencing. Let's test around the point $(0,0)$.
```{r}
delta <- 1e-7
(rb(0+delta,0) - rb(0,0))/delta
(rb(0,0+delta) - rb(0,0))/delta
rb.grad(0,0)
```

### Part (f)
```{r}
rb.hess <- function(x,z) {
  d <- deriv(expression(100*(z-x^2)^2 + (1-x)^2), namevec=c("x", "z"), hessian=TRUE, func=TRUE)
  attr(d(x,z), "hessian")[,,]
}

rb.hess(1,4)
```

### Part (g)
Test the `rb.hess` function via finite differencing the `rb.grad`.
```{r}
delta <- 1e-7

(rb.grad(0+delta, 0) - rb.grad(0, 0))/delta
(rb.grad(0, 0+delta) - rb.grad(0, 0))/delta
rb.hess(0,0)
```

### Part (h)
Taylor’s theorem implies that you can use rb, rb.grad and rb.hess to produce a ∗∗
quadratic function approximating f (x, z) in the neigbourhood of any particular point x , z . Write an R function to find such an approximation, given a point x∗, z∗, and to add a contour plot of the approximation to an existing contour plot of f (see add argument of contour). Your function should accept an argument col allowing you to set the colour of the contours of the quadratic approximation. Do make sure that the same transformation (if any) and levels are used when contouring the approximation and f itself.

```{r}
# function which produces a quadractic approximation and plots it
cont.approx <- function(x.star, z.star, col) {
  
  # define a function for the quadratic approximation
  quad.approx <- function(x,z) {rb(x.star,z.star) +    
      rb.grad(x.star,z.star)%*%c(x-x.star, z-z.star) + (t(c(x-x.star, z-z.star)) %*% rb.hess(x.star, z.star) %*% c(x-x.star, z-z.star))/2}
  
  cont.mat <- outer(x.seq,
                    z.seq,
                    Vectorize(function(x,z) log10(quad.approx(x,z))))
  
  contour(x.seq, z.seq, cont.mat, add=TRUE, col=col, levels=seq(-0.5,2.5, 0.5))
}

# approximate contour around (-1,0.5)
cont.mat <- outer(x.seq,
                  z.seq,
                  Vectorize(function(x,z) log10(rb(x,z))))
contour(x.seq, z.seq, cont.mat, levels = seq(-0.5,2.5, 0.5))
cont.approx(-1,0.5, col="red")

# approximate contour around (0,0)
cont.mat <- outer(x.seq,
                  z.seq,
                  Vectorize(function(x,z) log10(rb(x,z))))
contour(x.seq, z.seq, cont.mat, levels = seq(-0.5,2.5, 0.5))
cont.approx(0,0, col="red")

# approximate contour around (1,1)
cont.mat <- outer(x.seq,
                  z.seq,
                  Vectorize(function(x,z) log10(rb(x,z))))
contour(x.seq, z.seq, cont.mat, levels = seq(-0.5,2.5, 0.5))
cont.approx(1,1, col="red")
```

